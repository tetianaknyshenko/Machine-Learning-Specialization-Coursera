# Machine-Learning-Specialization-Coursera
Gradient Descent grad spusk

Derivative производная 
Convergence - сходимость:
 Факторы, влияющие на сходимость:
Learning Rate (Скорость обучения) — слишком большой шаг может привести к отсутствию сходимости, а слишком маленький — к очень медленной сходимости.
Форма функции потерь (Loss Function) — выпуклость функции помогает гарантировать сходимость.
Шум в данных — сильный шум может препятствовать достижению устойчивого минимума.


tangent line - kasatelmzfy
slope the tangent line - наклон касательной
Gradient descent:
https://towardsdatascience.com/gradient-descent-algorithm-a-deep-dive-cf04e8115f21
https://towardsdatascience.com/gradient-descent-algorithm-and-its-variants-10f652806a3#:~:text=In%20this%20article%2C%20we%E2%80%99ll%20cover%20gradient%20descent%20algorithm,before%20going%20into%20the%20details%20of%20its%20variants.
https://www.geeksforgeeks.org/difference-between-batch-gradient-descent-and-stochastic-gradient-descent/
